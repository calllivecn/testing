#!/usr/bin/env python3
# coding=utf-8
# date 2019-09-17 10:44:39
# author calllivecn <calllivecn@outlook.com>


"""
SIMD Autovectorization in Numba¶
WARNING: Due to CPU limitations on Binder, not all the benefits of SIMD instructions will be visible. You will see better SIMD performance if you download this notebook and run on Intel Haswell / AMD Zen or later.

Most modern CPUs have support for instructions that apply the same operation to multiple data elements simultaneously. These are called "Single Instruction, Multiple Data" (SIMD) operations, and the LLVM backend used by Numba can generate them in some cases to execute loops more quickly. (This process is called "autovectorization.")

For example, Intel processors have support for SIMD instruction sets like:

    SSE (128-bit inputs)
    AVX (256-bit inputs)
    AVX-512 (512-bit inputs, Skylake-X and later or Xeon Phi)
    These wide instructions typically operate on as many values as will fit into an input register. For AVX instructions, this means that either 8 float32 values or 4 float64 values can be processed as a single input. As a result, the NumPy dtype that you use can potentially impact performance to a greater degree than when SIMD is not in use.
"""
import time

import numpy as np
from numba import jit

"""
It can be somewhat tricky to determine when LLVM has successfully autovectorized a loop. The Numba team is working on exporting diagnostic information to show where the autovectorizer has generated SIMD code. For now, we can use a fairly crude approach of searching the assembly language generated by LLVM for SIMD instructions.

It is also interesting to note what kind of SIMD is used on your system. On x86_64, the name of the registers used indicates which level of SIMD is in use:

    SSE: xmmX
    AVX/AVX2: ymmX
    AVX-512: zmmX
    where X is an integer.

    Note: The method we use below to find SIMD instructions will only work on Intel/AMD CPUs. OtheBasic SIMD
Letr platforms have entirely different assembly language syntax for SIMD instructions.
"""

def find_instr(func, keyword, sig=0, limit=5):
    count = 0
    for l in func.inspect_asm(func.signatures[sig]).split('\n'):
        if keyword in l:
            count += 1
            print(l)
            if count >= limit:
                break
    if count == 0:
        print('No instructions found')

"""
Basic SIMD
Let's start with a simple function that returns the square difference between two arrays, as you might write for a least-squares optimization:
"""


@jit(nopython=True)
def sqdiff(x, y):
    out = np.empty_like(x)
    for i in range(x.shape[0]):
        out[i] = (x[i] - y[i])**2
    return out


x32 = np.linspace(1, 2, 10000, dtype=np.float32)
y32 = np.linspace(1, 3, 10000, dtype=np.float32)
sqdiff(x32, y32)

x64 = x32.astype(np.float64)
y64 = y32.astype(np.float64)
sqdiff(x64, y64)

sqdiff.signatures

start = time.time()
sqdiff(x32, y32)
print("运行时间：{}s".format(time.time() - start))

start = time.time()
sqdiff(x64, y64)
print("运行时间：{}s".format(time.time() - start))


# Numba has created two different implementations of the function, one for float32 1-D arrays, and one for float64 1-D arrays:


